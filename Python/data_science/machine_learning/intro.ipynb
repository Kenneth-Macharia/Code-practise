{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervise Learning\n",
    "\n",
    "- SL algorithms are trained using labelled input where the desired output is known e.g emails are already classified as legitimate or spam.\n",
    "- Using this historical data an ML algorithm / network can learn and then predict which 'label' category future data belongs to.\n",
    "- The network receives the data to predict outputs for alongside with the desired output, so as to compare its output against the correct ouptuts, to find prediction errors. then modifies its prediction model accordingly.\n",
    "- This algorithm id commonly used where historical events likely predict, future events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SL Workflow\n",
    "- Developing a SL prediction model involves the following steps:\n",
    "\n",
    "    1. Acquire the data from people(customer surveys), machines(sensors), web(scrapping) etc\n",
    "    2. Clean the data using tools like Pandas\n",
    "    3. Split the cleaned data i.e 30% (used to test the SL model) vs 70% (used to train the SL model)\n",
    "    4. Train and build the model by fit the model to the trainig data.\n",
    "    5. Run the test data through the model to compare it against the test data which has the desired output.\n",
    "    6. Adjust the model params to fine tune the model prediction.\n",
    "    7. Deploy the model to production if it performs accordingly.\n",
    "\n",
    "- In the real world, its not feasible to measure the true production performace of the SL model using the same data set that is used to train and refine the model. To get around this problem, the data set is actually split into 3:\n",
    "\n",
    "    1. Training Data: used to train and build the model\n",
    "    2. Validation Data: used to refine the model, by determining what model hyperparameters to adjust\n",
    "    3. Test Data: This usually unseen by the model thoughout the first two steps above and is used as       the final test of performance. After this test, then we can't refine the model anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics\n",
    "\n",
    "- These are the performance metrics categories to be used to evaluate the models and they include:\n",
    "\n",
    "    1. Accuracy: the number of correct predictions made by the model divided by total number of              predictions as a %. This metric is usefule when the target classes are well balanced i.e              predicting either cat or dog images, then we have roughly the same amount of images for both          categories. For unbalanced classes, the model will not be accurate due to the biased nature of        the training data.\n",
    "    2. Recall: ability of the mode to find all the relevant cases within a dataset. It is determined as number of true positives divided by number of true positives + number of false negatives.\n",
    "    3. Precision: ability of a classification model to id only the relevant data points and is determined as number of true positives divided by number of true positives plus number of false positives.\n",
    "    4. F1-Score: a combination of 2 & 3 above, and is the harmonic mean of the precision and the recall and is determined as 2*((precision * recall) / (precision + recall)). This preferred over a simple mean, as it 'punishes' extreme values e.g precision = 1.0 and recall = 0.0, where a simple mean would yield 0.5 but the f1-score for these values would be 0.0.\n",
    "\n",
    "_Recall and Precision trade-off: while recall expresses the ability to find all revelant instances in the dataset, precision expresses the proportion of the data points the model says was relevant that was actually relevant_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}